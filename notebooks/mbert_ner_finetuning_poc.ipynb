{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607f0b69-50e7-4625-80f5-735f990908d1",
   "metadata": {},
   "source": [
    "# Fine Tune Modern BERT for Named Entity Recognition Task\n",
    "### This notebook fine tunes modern BERT using the \"bigcode/pii-dataset\"  dataset for detecting Named entities and then recognize PII sensitive elements in the identified NER elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7138b3b4-61a3-4210-a522-272f52ae75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from transformers[torch]) (1.4.0)\n",
      "Requirement already satisfied: psutil in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pals/anaconda3/envs/prv_ner_att_tf_3_10/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers datasets seqeval torch\n",
    "!pip install --quiet tf_keras\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7331aabc-cb20-411a-8ee8-5df9f25ca405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c3c61-0cbd-452b-89a5-c67b19a88e19",
   "metadata": {},
   "source": [
    "# ****************************************\n",
    "# Configure the root of the Project Repo\n",
    "# ****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6dcb345-fb8a-4898-b287-cbf08c594aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "ROOTDIR =\"/Users/pals/MICS/MIDS_266/project/privacy-ner-att\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "169acb6f-e103-4158-bb9e-dac8152f133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01f04661-31e5-4364-b629-cd1e3052caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_ds = load_dataset(\"conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aaaf2ebd-d223-4cd5-bc47-40edd3a1e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "709ff070-2e1e-4ccf-99a1-a55c032ad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ele = conll_ds['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a4b5f8d-f053-4f61-8597-ae11f71c1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    print(ds_ele['tokens'], len(ds_ele['tokens']))\n",
    "    print(ds_ele['pos_tags'], len(ds_ele['pos_tags']))\n",
    "    print(ds_ele['chunk_tags'], len(ds_ele['chunk_tags']))\n",
    "    print(ds_ele['ner_tags'], len(ds_ele['ner_tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0d0776d-1abe-4641-abb3-a1d15f95f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags   = conll_ds[\"train\"].features[\"pos_tags\"].feature.names\n",
    "chunk_tags = conll_ds[\"train\"].features[\"chunk_tags\"].feature.names\n",
    "ner_tags   = conll_ds[\"train\"].features[\"ner_tags\"].feature.names\n",
    "if debug:\n",
    "    print(ner_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74098503-671a-4a18-8bf4-9efa290e1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_id2tag   = { k: v for k,v in enumerate(pos_tags)}\n",
    "chunk_id2tag = { k: v for k,v in enumerate(chunk_tags)}\n",
    "ner_id2tag   = { k: v for k,v in enumerate(ner_tags)}\n",
    "if debug:\n",
    "    print(ner_id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cbdd13e-7a68-4e43-a392-0fcbdec05bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag2id   = { v: k for k,v in enumerate(pos_tags)}\n",
    "chunk_tag2id = { v: k for k,v in enumerate(chunk_tags)}\n",
    "ner_tag2id   = { v: k for k,v in enumerate(ner_tags)}\n",
    "if debug:\n",
    "    print(ner_tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2547b7b2-8668-4b25-b758-f938cc4403f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ner_ids_to_label(ner_ids: list) -> list[str]:\n",
    "    return [ner_id2tag[i] for i in ner_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffbede80-c0dc-4c0d-9c1b-bec00638a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"answerdotai/ModernBERT-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ab410e4-418e-4d8d-a199-45663e98ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb7bd80a-1a72-4153-b1e7-f7d3ef4657c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_ner_tags(conll_ds: dict, tokenizer: object) -> None:\n",
    "    input_tokens = tokenizer(conll_ds['tokens'], \n",
    "                             truncation=True, \n",
    "                             padding=\"max_length\",  # Ensure fixed input size\n",
    "                             max_length=MAX_SEQ_LENGTH,        # Set max token limit\n",
    "                             is_split_into_words=True)\n",
    "    input_labels = []\n",
    "    for i, ner_tag_i in enumerate(conll_ds['ner_tags']):\n",
    "        # For each ner_tag line associated with input sentence\n",
    "        # get the tokenized word ids and then associated the \n",
    "        # ner_label. Note: word_ids is not the actual tokens, rather it is \n",
    "        # just word index corresponding to original input\n",
    "        word_ids = input_tokens.word_ids(batch_index=i) \n",
    "        aligned_ner_tag = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_ner_tag.append(-100)\n",
    "            else:\n",
    "                aligned_ner_tag.append(ner_tag_i[word_id]) \n",
    "        while len(aligned_ner_tag) < MAX_SEQ_LENGTH:\n",
    "            aligned_ner_tag.append(-100)\n",
    "        input_labels.append(aligned_ner_tag)\n",
    "        if debug:\n",
    "            if i == 0:\n",
    "                print(\"input tokens \", i, conll_ds['tokens'][i])\n",
    "                print(\"NER IDS      \", i, ner_tag_i)\n",
    "                print(\"NER Labels   \", i, convert_ner_ids_to_label(ner_tag_i))\n",
    "                print(\"Word Ids     \", i, input_tokens.word_ids(batch_index=i))\n",
    "                print(\"Aligned NER  \", i, aligned_ner_tag)\n",
    "    input_tokens['labels'] = input_labels\n",
    "    return input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "777539da-c236-428c-80d4-3c9f2fbba325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████| 3250/3250 [00:00<00:00, 22521.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "conll_ds = conll_ds.map(tokenize_and_align_ner_tags, batched=True, fn_kwargs={'tokenizer': mbert_tokenizer})\n",
    "conll_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874a822-3c0c-4b08-a091-33feac334f81",
   "metadata": {},
   "source": [
    "# Prepare the MBert configuration for creating the Modern Bert Classifier task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb48fba7-b934-4350-84c4-68fccefbe63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert_config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels = len(ner_tags),\n",
    "    id2label = ner_id2tag,\n",
    "    label2ids = ner_tag2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af20788f-1d23-490f-806c-0058feb13b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mbert_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=mbert_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ac26eb1-9822-4c02-b151-b95154e80a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModernBertForTokenClassification(\n",
       "  (model): ModernBertModel(\n",
       "    (embeddings): ModernBertEmbeddings(\n",
       "      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModernBertEncoderLayer(\n",
       "        (attn_norm): Identity()\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertRotaryEmbedding()\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1-21): 21 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertRotaryEmbedding()\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): ModernBertPredictionHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (act): GELUActivation()\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(f\"Loading model to device: {device}\")\n",
    "mbert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7587b229-ccab-46fb-a313-6131bd73b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = np.argmax(logits, axis=2)\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for label_row, pred_row in zip(labels, predictions):  # Process each sentence\n",
    "        temp_true = []\n",
    "        temp_pred = []\n",
    "        \n",
    "        for label_id, pred_id in zip(label_row, pred_row):  # Process each token\n",
    "            if label_id != -100:  # Ignore padding tokens\n",
    "                temp_true.append(ner_id2tag[label_id])  # Convert true label to string\n",
    "                temp_pred.append(ner_id2tag[pred_id])  # Convert predicted label to string\n",
    "\n",
    "        if temp_true:  # Only add non-empty sequences\n",
    "            true_labels.append(temp_true)\n",
    "            pred_labels.append(temp_pred)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels),\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "469765a1-21a3-4d91-942c-20e0452995d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL   = \"mbert\"\n",
    "OUTDIR  = f\"{ROOTDIR}/build/{MODEL}/results\"\n",
    "LOGDIR  = f\"{ROOTDIR}/build/{MODEL}/logs\"\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "WT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58c825cf-2b18-405d-ad62-0249dbbcdf6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTDIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=WT_DECAY,\n",
    "    logging_dir=LOGDIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3877547-290d-46aa-bc9e-d2dc97e834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=mbert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=conll_ds[\"train\"],\n",
    "    eval_dataset=conll_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f698a53-e185-411b-ae9d-7b29041757d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17560' max='17560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17560/17560 2:04:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.076213</td>\n",
       "      <td>0.981009</td>\n",
       "      <td>0.927840</td>\n",
       "      <td>0.928048</td>\n",
       "      <td>0.927633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.080684</td>\n",
       "      <td>0.982083</td>\n",
       "      <td>0.932210</td>\n",
       "      <td>0.930373</td>\n",
       "      <td>0.934055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.079557</td>\n",
       "      <td>0.981858</td>\n",
       "      <td>0.929151</td>\n",
       "      <td>0.921608</td>\n",
       "      <td>0.936819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>0.982548</td>\n",
       "      <td>0.936286</td>\n",
       "      <td>0.933160</td>\n",
       "      <td>0.939432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.116714</td>\n",
       "      <td>0.983357</td>\n",
       "      <td>0.937702</td>\n",
       "      <td>0.931790</td>\n",
       "      <td>0.943689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.112998</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.929968</td>\n",
       "      <td>0.925770</td>\n",
       "      <td>0.934205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.113267</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.942995</td>\n",
       "      <td>0.942748</td>\n",
       "      <td>0.943241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.945334</td>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.944063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.125750</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>0.937699</td>\n",
       "      <td>0.945332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.128712</td>\n",
       "      <td>0.984921</td>\n",
       "      <td>0.942687</td>\n",
       "      <td>0.939540</td>\n",
       "      <td>0.945855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17560, training_loss=0.02277638827147801, metrics={'train_runtime': 7459.6955, 'train_samples_per_second': 18.822, 'train_steps_per_second': 2.354, 'total_flos': 1.196203276493568e+16, 'train_loss': 0.02277638827147801, 'epoch': 10.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d0de562-0b4c-414f-b0de-bd1a0f37f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner(text, tokenizer, model):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Loading model to device: {device}\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    tokens = {key: value.to(device) for key, value in tokens.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    predicted_labels = [ner_id2tag[id.item()] for id in predictions[0]]\n",
    "\n",
    "    return list(zip(tokenizer.tokenize(text), predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a3b9d54-7868-4adf-bd93-8d5563986b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to device: mps\n",
      "[('Kenn', 'O'), ('edy', 'B-PER'), ('Ġdelivered', 'B-PER'), ('Ġhis', 'O'), ('Ġfamous', 'O'), ('Ġspeech', 'O'), ('Ġat', 'O'), ('ĠRice', 'O'), ('ĠUniversity', 'B-ORG'), ('.', 'I-ORG')]\n"
     ]
    }
   ],
   "source": [
    "# Test with a news sentence\n",
    "text = \"Kennedy delivered his famous speech at Rice University.\"\n",
    "print(predict_ner(text, mbert_tokenizer, mbert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c3a6d-6abc-4d14-8cc9-11f765c76550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Privacy NER Attention Python 3.10",
   "language": "python",
   "name": "prv_ner_att_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
